{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r910EfCS4ojz",
        "outputId": "353f1aa1-8bab-4b84-c0a1-166e03d64e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/continous_magnet'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 188 (delta 90), reused 178 (delta 84), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (188/188), 92.13 KiB | 1.51 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "/content/continous_magnet\n",
            "total 32\n",
            "drwxr-xr-x 7 root root 4096 Mar 10 00:43  .\n",
            "drwxr-xr-x 1 root root 4096 Mar 10 00:43  ..\n",
            "drwxr-xr-x 8 root root 4096 Mar 10 00:43  .git\n",
            "drwxr-xr-x 4 root root 4096 Mar 10 00:43  Magnet\n",
            "drwxr-xr-x 4 root root 4096 Mar 10 00:43 'Magnet plus vmf'\n",
            "-rw-r--r-- 1 root root  538 Mar 10 00:43  Readme.txt\n",
            "drwxr-xr-x 4 root root 4096 Mar 10 00:43  Triplet\n",
            "drwxr-xr-x 2 root root 4096 Mar 10 00:43  VMF\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/continous_magnet\n",
        "!git clone https://github.com/GitHubSamm/continous_magnet.git /content/continous_magnet\n",
        "%cd /content/continous_magnet\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/continous_magnet/Magnet')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "xFiX69IFdzEK",
        "outputId": "a1031741-3205-44a9-ec53-c1c162d05f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/continous_magnet/Magnet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result obtained with:\n",
        "\n",
        "$Facnet_config = {\n",
        "    \"Epochs\" : 50,               # Number of epochs\n",
        "    \"learning_rate\" : 10**-4,     # learning rate\n",
        "    \"epsilon\" : 1e-8,             # epsilon to avoid 0 in denum in loss function\n",
        "    \"alpha\" : 1,                  # Margin alpha for magnet loss\n",
        "    \"nb_clusters\" : [20,20,20,20,20,20,20,20,20,20],     # Number of clusters per class\n",
        "    \"M\" : 16,                     # Number of clusters present in a mini-batch\n",
        "    \"D\" : 8,                      # Number of smaples selected from each cluster in the mini-batch\n",
        "    \"K\" : 15,                     # K for K-nearest neighbors\n",
        "    \"L\" : 3,                      # L number of nearest clusters used to predict the label of a given query (instead of KNN: magnet evaluation)\n",
        "    \"nb_batches\" : 30,            \n",
        "    \"list_classes\" : [0,1,2,3,4,5,6,7,8,9],       # List of classes\n",
        "    \"batch_size\" : 32,            # mini batch size to forward the data (out of training)\n",
        "    \"optimizer_flag\" : 'Adam',    # Optimizer\n",
        "    \"width\" : 2,                  # width of wide residual block\n",
        "}$"
      ],
      "metadata": {
        "id": "AXvAyDqRmQbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/continous_magnet/Magnet/main.py"
      ],
      "metadata": {
        "id": "ClfnJBoUeazO",
        "outputId": "6fc14064-1ccd-4ebf-d7f6-50c9a4b0b80a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "images_train size: torch.Size([5000, 3, 32, 32])\n",
            "labels_train size: torch.Size([5000])\n",
            "images_test size: torch.Size([1000, 3, 32, 32])\n",
            "labels_test size: torch.Size([1000])\n",
            "   #######################  Train Epoch: 0 train_acc: 0.2872  test_acc: 0.2760 ###################       \n",
            "   #######################  Train Epoch: 1 train_acc: 0.3716  test_acc: 0.3470 ###################       \n",
            "   #######################  Train Epoch: 2 train_acc: 0.4310  test_acc: 0.3820 ###################       \n",
            "   #######################  Train Epoch: 3 train_acc: 0.4690  test_acc: 0.4170 ###################       \n",
            "   #######################  Train Epoch: 4 train_acc: 0.5040  test_acc: 0.4120 ###################       \n",
            "   #######################  Train Epoch: 5 train_acc: 0.5172  test_acc: 0.4280 ###################       \n",
            "   #######################  Train Epoch: 6 train_acc: 0.5614  test_acc: 0.4340 ###################       \n",
            "   #######################  Train Epoch: 7 train_acc: 0.5906  test_acc: 0.4290 ###################       \n",
            "   #######################  Train Epoch: 8 train_acc: 0.6130  test_acc: 0.4550 ###################       \n",
            "   #######################  Train Epoch: 9 train_acc: 0.6332  test_acc: 0.4410 ###################       \n",
            "   #######################  Train Epoch: 10 train_acc: 0.6438  test_acc: 0.4490 ###################       \n",
            "   #######################  Train Epoch: 11 train_acc: 0.6780  test_acc: 0.4320 ###################       \n",
            "   #######################  Train Epoch: 12 train_acc: 0.6984  test_acc: 0.4580 ###################       \n",
            "   #######################  Train Epoch: 13 train_acc: 0.7142  test_acc: 0.4380 ###################       \n",
            "   #######################  Train Epoch: 14 train_acc: 0.7352  test_acc: 0.4510 ###################       \n",
            "   #######################  Train Epoch: 15 train_acc: 0.7430  test_acc: 0.4580 ###################       \n",
            "   #######################  Train Epoch: 16 train_acc: 0.7460  test_acc: 0.4580 ###################       \n",
            "   #######################  Train Epoch: 17 train_acc: 0.7682  test_acc: 0.4390 ###################       \n",
            "   #######################  Train Epoch: 18 train_acc: 0.7666  test_acc: 0.4560 ###################       \n",
            "   #######################  Train Epoch: 19 train_acc: 0.7814  test_acc: 0.4320 ###################       \n",
            "   #######################  Train Epoch: 20 train_acc: 0.7894  test_acc: 0.4510 ###################       \n",
            "   #######################  Train Epoch: 21 train_acc: 0.8092  test_acc: 0.4490 ###################       \n",
            "   #######################  Train Epoch: 22 train_acc: 0.7962  test_acc: 0.4580 ###################       \n",
            "   #######################  Train Epoch: 23 train_acc: 0.8228  test_acc: 0.4640 ###################       \n",
            "   #######################  Train Epoch: 24 train_acc: 0.8408  test_acc: 0.4680 ###################       \n",
            "   #######################  Train Epoch: 25 train_acc: 0.8472  test_acc: 0.4640 ###################       \n",
            "   #######################  Train Epoch: 26 train_acc: 0.8438  test_acc: 0.4600 ###################       \n",
            "   #######################  Train Epoch: 27 train_acc: 0.8566  test_acc: 0.4730 ###################       \n",
            "   #######################  Train Epoch: 28 train_acc: 0.8500  test_acc: 0.4650 ###################       \n",
            "   #######################  Train Epoch: 29 train_acc: 0.8694  test_acc: 0.4510 ###################       \n",
            "   #######################  Train Epoch: 30 train_acc: 0.8844  test_acc: 0.4680 ###################       \n",
            "   #######################  Train Epoch: 31 train_acc: 0.8816  test_acc: 0.4600 ###################       \n",
            "   #######################  Train Epoch: 32 train_acc: 0.8594  test_acc: 0.4660 ###################       \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/continous_magnet/Magnet/main.py\", line 50, in <module>\n",
            "    learning_function(model,optimizer,device,images_train, labels_train,images_test,labels_test)\n",
            "  File \"/content/continous_magnet/Magnet/learning_function.py\", line 62, in learning_function\n",
            "    loss   = loss_function(alpha).forward(output, batch_label,chosen_clusters,device).to(device)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/continous_magnet/Magnet/loss_function.py\", line 37, in forward\n",
            "    dis        = -(1/(2*sigma.pow(2)))*self.pdist(output[s],mean_clusters).pow(2)\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/distance.py\", line 58, in forward\n",
            "    return F.pairwise_distance(x1, x2, self.norm, self.eps, self.keepdim)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result obtained with:\n",
        "\n",
        "$Facnet_config = {\n",
        "    \"Epochs\" : 50,               # Number of epochs\n",
        "    \"learning_rate\" : 10**-4,     # learning rate\n",
        "    \"epsilon\" : 1e-8,             # epsilon to avoid 0 in denum in loss function\n",
        "    \"alpha\" : 1,                  # Margin alpha for magnet loss\n",
        "    \"nb_clusters\" : [20,20,20,20,20,20,20,20,20,20],     # Number of clusters per class\n",
        "    \"M\" : 16,                     # Number of clusters present in a mini-batch\n",
        "    \"D\" : 8,                      # Number of smaples selected from each cluster in the mini-batch\n",
        "    \"K\" : 15,                     # K for K-nearest neighbors\n",
        "    \"L\" : 128,                      # L number of nearest clusters used to predict the label of a given query (instead of KNN: magnet evaluation)\n",
        "    \"nb_batches\" : 30,            \n",
        "    \"list_classes\" : [0,1,2,3,4,5,6,7,8,9],       # List of classes\n",
        "    \"batch_size\" : 32,            # mini batch size to forward the data (out of training)\n",
        "    \"optimizer_flag\" : 'Adam',    # Optimizer\n",
        "    \"width\" : 2,                  # width of wide residual block\n",
        "}$"
      ],
      "metadata": {
        "id": "xrL7xeyFgYx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/continous_magnet/Magnet/main.py"
      ],
      "metadata": {
        "id": "C04EeRF0vRds",
        "outputId": "22bedd5c-3a8e-4c45-ef98-a55441a95252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "images_train size: torch.Size([20000, 3, 32, 32])\n",
            "labels_train size: torch.Size([20000])\n",
            "images_test size: torch.Size([4000, 3, 32, 32])\n",
            "labels_test size: torch.Size([4000])\n",
            "   #######################  Train Epoch: 0 train_acc: 0.3268  test_acc: 0.3137 ###################       \n",
            "   #######################  Train Epoch: 1 train_acc: 0.4043  test_acc: 0.4017 ###################       \n",
            "   #######################  Train Epoch: 2 train_acc: 0.4351  test_acc: 0.4268 ###################       \n",
            "   #######################  Train Epoch: 3 train_acc: 0.4636  test_acc: 0.4500 ###################       \n",
            "   #######################  Train Epoch: 4 train_acc: 0.4738  test_acc: 0.4640 ###################       \n",
            "   #######################  Train Epoch: 5 train_acc: 0.4948  test_acc: 0.4753 ###################       \n",
            "   #######################  Train Epoch: 6 train_acc: 0.5064  test_acc: 0.4865 ###################       \n",
            "   #######################  Train Epoch: 7 train_acc: 0.5151  test_acc: 0.4968 ###################       \n",
            "   #######################  Train Epoch: 8 train_acc: 0.5249  test_acc: 0.4973 ###################       \n",
            "   #######################  Train Epoch: 9 train_acc: 0.5244  test_acc: 0.4990 ###################       \n",
            "   #######################  Train Epoch: 10 train_acc: 0.5383  test_acc: 0.4990 ###################       \n",
            "   #######################  Train Epoch: 11 train_acc: 0.5382  test_acc: 0.4993 ###################       \n",
            "   #######################  Train Epoch: 12 train_acc: 0.5441  test_acc: 0.5038 ###################       \n",
            "   #######################  Train Epoch: 13 train_acc: 0.5512  test_acc: 0.5100 ###################       \n",
            "   #######################  Train Epoch: 14 train_acc: 0.5591  test_acc: 0.5095 ###################       \n",
            "   #######################  Train Epoch: 15 train_acc: 0.5675  test_acc: 0.5240 ###################       \n",
            "   #######################  Train Epoch: 16 train_acc: 0.5756  test_acc: 0.5202 ###################       \n",
            "   #######################  Train Epoch: 17 train_acc: 0.5728  test_acc: 0.5145 ###################       \n",
            "   #######################  Train Epoch: 18 train_acc: 0.5788  test_acc: 0.5312 ###################       \n",
            "   #######################  Train Epoch: 19 train_acc: 0.5868  test_acc: 0.5212 ###################       \n",
            "   #######################  Train Epoch: 20 train_acc: 0.5965  test_acc: 0.5343 ###################       \n",
            "   #######################  Train Epoch: 21 train_acc: 0.6043  test_acc: 0.5308 ###################       \n",
            "   #######################  Train Epoch: 22 train_acc: 0.6072  test_acc: 0.5280 ###################       \n",
            "   #######################  Train Epoch: 23 train_acc: 0.6093  test_acc: 0.5225 ###################       \n",
            "   #######################  Train Epoch: 24 train_acc: 0.6102  test_acc: 0.5383 ###################       \n",
            "   #######################  Train Epoch: 25 train_acc: 0.6203  test_acc: 0.5327 ###################       \n",
            "   #######################  Train Epoch: 26 train_acc: 0.6227  test_acc: 0.5357 ###################       \n",
            "   #######################  Train Epoch: 27 train_acc: 0.6245  test_acc: 0.5335 ###################       \n",
            "   #######################  Train Epoch: 28 train_acc: 0.6309  test_acc: 0.5393 ###################       \n",
            "   #######################  Train Epoch: 29 train_acc: 0.6404  test_acc: 0.5407 ###################       \n",
            "   #######################  Train Epoch: 30 train_acc: 0.6435  test_acc: 0.5453 ###################       \n",
            "   #######################  Train Epoch: 31 train_acc: 0.6370  test_acc: 0.5390 ###################       \n",
            "   #######################  Train Epoch: 32 train_acc: 0.6511  test_acc: 0.5403 ###################       \n",
            "   #######################  Train Epoch: 33 train_acc: 0.6584  test_acc: 0.5450 ###################       \n",
            "   #######################  Train Epoch: 34 train_acc: 0.6595  test_acc: 0.5423 ###################       \n",
            "   #######################  Train Epoch: 35 train_acc: 0.6650  test_acc: 0.5427 ###################       \n",
            "   #######################  Train Epoch: 36 train_acc: 0.6715  test_acc: 0.5390 ###################       \n",
            "   #######################  Train Epoch: 37 train_acc: 0.6790  test_acc: 0.5420 ###################       \n",
            "   #######################  Train Epoch: 38 train_acc: 0.6783  test_acc: 0.5455 ###################       \n",
            "   #######################  Train Epoch: 39 train_acc: 0.6854  test_acc: 0.5370 ###################       \n",
            "   #######################  Train Epoch: 40 train_acc: 0.6992  test_acc: 0.5427 ###################       \n",
            "   #######################  Train Epoch: 41 train_acc: 0.6977  test_acc: 0.5520 ###################       \n",
            "   #######################  Train Epoch: 42 train_acc: 0.7113  test_acc: 0.5557 ###################       \n",
            "   #######################  Train Epoch: 43 train_acc: 0.7050  test_acc: 0.5423 ###################       \n",
            "   #######################  Train Epoch: 44 train_acc: 0.7089  test_acc: 0.5533 ###################       \n",
            "   #######################  Train Epoch: 45 train_acc: 0.7085  test_acc: 0.5510 ###################       \n",
            "   #######################  Train Epoch: 46 train_acc: 0.7108  test_acc: 0.5493 ###################       \n",
            "   #######################  Train Epoch: 47 train_acc: 0.7228  test_acc: 0.5545 ###################       \n",
            "   #######################  Train Epoch: 48 train_acc: 0.7266  test_acc: 0.5483 ###################       \n",
            "   #######################  Train Epoch: 49 train_acc: 0.7384  test_acc: 0.5553 ###################       \n",
            "   #######################  Train Epoch: 50 train_acc: 0.7356  test_acc: 0.5585 ###################       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZdG1cbZrpkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}